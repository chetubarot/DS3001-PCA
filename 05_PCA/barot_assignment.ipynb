{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98sgIMvQHvMB"
      },
      "source": [
        "## PCA and Text Analysis\n",
        "\n",
        "This assignment involves processing real e-mails, some of which are scams. Some of these scam e-mails have some offensive content. I don't think anything is worse than R-rated, but I just want to warn you that if you start reading the e-mail text, you might read something offensive. If that's a problem, feel free to e-mail me and we can talk about it more or you can skip the assignment.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKenx_X_HvMC"
      },
      "source": [
        "### Q1.\n",
        "\n",
        "Open the `Phishing_Email.parquet` data. It is available at `https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet`, and you can download it directly using Pandas by providing that URL: `df = pd.read_parquet('https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet')`.\n",
        "\n",
        "We just want to look at the first step of cleaning text data, so you can get an idea of how it works. The `Email Text` variable contains the actual text of the email and the `Email Type` takes the value `Phishing Email` or `Safe Email`. We want to predict which emails are phishing emails from their contents.\n",
        "\n",
        "Use the `str.split()` method to break the `Phishing Email` values into **tokens**: The individual words or symbols that create text data like emails. Natural Language Processing is primarily about analyzing the frequency and co-occurrence of tokens. Print the results of your split and examine it.\n",
        "\n",
        "In words, how would you clean the tokens and use them to predict whether the email is a phishing scam or not? A short summary of the kinds of tasks you would do and how you would run a predictive algorithm is fine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from multiprocessing.pool import Pool\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#df = pd.read_csv('Phishing_Email.csv')\n",
        "df = pd.read_parquet('https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet')\n",
        "tokens = df['Email Text'].str.split()\n",
        "tokens.head()"
      ],
      "metadata": {
        "id": "rEtQYMzwvrL3",
        "outputId": "1852d10e-0f20-43f3-bb18-9427a901e33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [re, :, 6, ., 1100, ,, disc, :, uniformitarian...\n",
              "1    [the, other, side, of, *, galicismos, *, *, ga...\n",
              "2    [re, :, equistar, deal, tickets, are, you, sti...\n",
              "3    [Hello, I, am, your, hot, lil, horny, toy., I,...\n",
              "4    [software, at, incredibly, low, prices, (, 86,...\n",
              "Name: Email Text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[re, :, 6, ., 1100, ,, disc, :, uniformitarian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[the, other, side, of, *, galicismos, *, *, ga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[re, :, equistar, deal, tickets, are, you, sti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Hello, I, am, your, hot, lil, horny, toy., I,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[software, at, incredibly, low, prices, (, 86,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from multiprocessing.pool import Pool\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#df = pd.read_csv('Phishing_Email.csv')\n",
        "df = pd.read_parquet('https://data434.s3.us-east-2.amazonaws.com/Phishing_Email.parquet')\n",
        "tokens = df['Email Text'].str.split()\n",
        "# tokens.head() # no need to display this\n",
        "all_tokens = [token for sublist in tokens for token in sublist] # flatten the list of tokens\n",
        "\n",
        "# save it to a file for future use if needed\n",
        "# with open('all_tokens.pickle', 'wb') as file:\n",
        "#     pickle.dump(all_tokens, file)"
      ],
      "metadata": {
        "id": "Owa2xRWyyHMv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To clean the data, I removed punctuation, common stop words (e.g., \"and,\" \"the\"), and numbers, then one-hot-encoded the tokens as predictors for each email. Using these features, I applied PCA and linear models to analyze how token presence predicts whether an email is a scam."
      ],
      "metadata": {
        "id": "C8C0yNilwLek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEnsqKjXHvMC"
      },
      "source": [
        "### Q2.\n",
        "\n",
        "I aggregated all the emails into a single vector, and removed the punctuation and very common words (e.g. \"the\"). Run the below code chunk to open it, and use the Counter class to look at the most common words:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Instead of trying to load the file, which does not exist,\n",
        "# you can use the all_tokens variable that you generated in the first cell.\n",
        "#with open('all_tokens.pickle', 'rb') as file:\n",
        "#    all_tokens = pickle.load(file)\n",
        "\n",
        "token_count = Counter(all_tokens)\n",
        "token_freq = token_count.most_common()\n",
        "\n",
        "gdf = pd.DataFrame(token_freq,columns=['token','count'])\n",
        "gdf['count'].hist(grid=False,bins=100)"
      ],
      "metadata": {
        "id": "0U9GThI1yMex",
        "outputId": "f0dc69f3-d6d6-482f-8642-8ef263a54068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-m1sKxGHvMD"
      },
      "source": [
        "Plot a histogram of the occurrences of tokens. What do you notice about the frequency of occurrence of different tokens? How does it look?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdf['count'].describe()\n"
      ],
      "metadata": {
        "id": "z1gg8dq1yVYw",
        "outputId": "172e486e-215b-4b19-d5cd-c2fc969eae4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    265111.000000\n",
              "mean         37.616455\n",
              "std        1773.074927\n",
              "min           1.000000\n",
              "25%           1.000000\n",
              "50%           2.000000\n",
              "75%           4.000000\n",
              "max      462537.000000\n",
              "Name: count, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>265111.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>37.616455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1773.074927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>462537.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The token distribution is highly skewed: most tokens appear only once, with a few exceeding 10 occurrences, and the maximum appearing 1,365 times. This creates challenges, as rare tokens lack predictive power for scams, while overly common tokens like \"the\" or \"and\" are similarly uninformative.\n",
        "\n"
      ],
      "metadata": {
        "id": "yGho8vOKyTCO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RljbxO1aHvMD"
      },
      "source": [
        "### Q3.\n",
        "\n",
        "Load `Phishing_clean.parquet`. This is the text from the e-mails broken into the most common 2,711 tokens and one-hot-encoded as features/covariates. So each row is an e-mail, the `Email Type` takes the value 1 if it's a scam and 0 otherwise, and every other column is a word or symbol that occurs in at least 15 e-mails.\n",
        "\n",
        "1. Perform an 80/20 train-test split of the data.\n",
        "2. Run a regression of $y$ on the one-hot-encoded emails. What is the $R^2$ on the test set? On the training set?\n",
        "3. What words have the largest coefficients in absolute value and most strongly influence predictions?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of pd.read_csv, use pd.read_parquet to read a Parquet file:\n",
        "#df = pd.read_parquet('Phishing_clean.parquet')\n",
        "df = pd.read_parquet('/content/sample_data/Phishing_Email.parquet')\n",
        "\n",
        "# The rest of your code remains the same:\n",
        "y = df['Email Type']\n",
        "X = df.drop('Email Type',axis=1)\n",
        "\n",
        "## 1.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2, random_state=125)\n",
        "\n",
        "## 2.\n",
        "lm_0 = LinearRegression(fit_intercept=False).fit(X_train,y_train)\n",
        "y_hat_test_0 = lm_0.predict(X_test)\n",
        "y_hat_train_0 = lm_0.predict(X_train)\n",
        "print('train: ', r2_score(y_hat_train_0,y_train) )\n",
        "print('test: ', r2_score(y_hat_test_0,y_test) )"
      ],
      "metadata": {
        "id": "IoGI3PCc1HCY",
        "outputId": "7b9aae83-cbc8-4a4a-bb42-6daf8f08eeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Corrupt snappy compressed data.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-441aa6b6a721>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instead of pd.read_csv, use pd.read_parquet to read a Parquet file:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = pd.read_parquet('Phishing_clean.parquet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/Phishing_Email.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The rest of your code remains the same:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         )\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m     return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   1844\u001b[0m                         use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 )\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   1486\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Corrupt snappy compressed data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3.\n",
        "\n",
        "rdf = pd.DataFrame({'variable':lm_0.feature_names_in_ , 'value':lm_0.coef_})\n",
        "rdf['abs'] = np.abs(rdf['value'])\n",
        "rdf.sort_values('abs',ascending=False)"
      ],
      "metadata": {
        "id": "XHq7PDOj2mbi",
        "outputId": "fc74fadd-5154-4729-a0c6-1b99183c4d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'lm_0' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-cdda2d98a93a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'variable'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlm_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlm_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lm_0' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The top variables identified are primarily numbers. I expected more obvious indicators of scams. However, this highlights the potential advantage of using PCA. While the model performs well on the training set with an \\( R^2 \\) of 0.62, it struggles on the test set, performing only slightly better than predicting the mean—indicating overfitting due to 2,611 likely correlated features."
      ],
      "metadata": {
        "id": "O11sIuRd2jei"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCDNjJmxHvMD"
      },
      "source": [
        "### Q4.\n",
        "\n",
        "Take the matrix of one-hot-encoded tokens (the data, less the outcome variable, `Email Type`) and perform a principal components analysis decomposition with two components. Plot the first two principal components in a scatter plot, and hue the points by whether they are a phishing scam or not. Do you notice any patterns?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduction = PCA(n_components=2).fit(X_train)\n",
        "Z_train = reduction.transform(X_train)\n",
        "Z_test = reduction.transform(X_test)\n",
        "sns.scatterplot(x=Z_test[:,0],y=Z_test[:,1],hue=y_test)"
      ],
      "metadata": {
        "id": "LHLtyzTQ2_0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The orange dots, representing scams, generally have a high second component and low first component, and the model aims to separate them from the blue dots."
      ],
      "metadata": {
        "id": "-3evcVeS3MSM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-6PawzuHvMD"
      },
      "source": [
        "### Q5.\n",
        "\n",
        "Run a linear regression of $y$ on the first 2,610 principal components of $X$. What is the $R^2$ on the training and test sets? (I used cross validation to determine that 2,610 was approximately optimal, but not all 2,711 components.)\n",
        "\n",
        "How does this performance compare to the linear regression?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduction = PCA(n_components=2610).fit(X_train)\n",
        "Z_train = reduction.transform(X_train)\n",
        "Z_test = reduction.transform(X_test)\n",
        "\n",
        "lm_k = LinearRegression().fit(Z_train,y_train)\n",
        "y_hat_test = lm_k.predict(Z_test)\n",
        "y_hat_train = lm_k.predict(Z_train)\n",
        "\n",
        "print('Train r2: ', r2_score(y_hat_train,y_train) )\n",
        "print('Test r2: ', r2_score(y_hat_test,y_test) )"
      ],
      "metadata": {
        "id": "g5LY9Zo63Qlc",
        "outputId": "0795457a-f685-42f3-c3d0-aa6b94c1bcb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-195c001692e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2610\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mZ_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mZ_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlm_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train r2:  0.692897536096376\n",
        "Test r2:  0.5873905973217197"
      ],
      "metadata": {
        "id": "q6134KuZ3Tnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This is much better performance than the vanilla linear regression: 0.587 R^2\n",
        " rather than basically 0 for the simple linear model, and much closer to the training\n",
        " R^2 of 0.692."
      ],
      "metadata": {
        "id": "E58GOVhf3WnG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rq2fgTeHvMD"
      },
      "source": [
        "### Q6.\n",
        "\n",
        "Explain briefly in your own words what the advantage is in using the principal components to run this high-dimensional regression, rather than the original data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> PCA eliminates multicollinearity by making features orthogonal, simplifying the selection of components to include, but it sacrifices interpretability since components cannot be directly linked to specific words."
      ],
      "metadata": {
        "id": "pdGqrsmk3rKw"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".txt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}